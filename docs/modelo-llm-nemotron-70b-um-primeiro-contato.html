<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Modelo LLM Nemotron 70B: Um primeiro contato &ndash; giseldo</title>

    <!-- Meta -->
    <meta name="description" content="giseldo &ndash; Um Blog sobre Inteligência Artificial">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Social -->
    <meta property="article:author" content="Giseldo Neo" />
    <meta property="article:section" content="Blog" />
    <meta property="article:published_time" content="2024-10-22" />

    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Modelo LLM Nemotron 70B: Um primeiro contato"/>
    <meta property="og:description" content="Um primeiro contato com o LLM Nemotron"/>
    <meta property="og:site_name" content="giseldo" />
    <meta property="og:url" content="/modelo-llm-nemotron-70b-um-primeiro-contato.html"/>

    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Modelo LLM Nemotron 70B: Um primeiro contato">
    <meta name="twitter:description" content="Um primeiro contato com o LLM Nemotron">
    <meta name="twitter:url" content="/modelo-llm-nemotron-70b-um-primeiro-contato.html">

    <!-- Feed -->
    <link rel="alternate" type="application/rss+xml" href="http://giseldo.disqus.com/latest.rss" title="giseldo Comments RSS Feed">

    <!-- CSS -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Open+Sans:regular,bold">
    <link rel="stylesheet" type="text/css" href="/theme/css/w3.css">
    <link rel="stylesheet" type="text/css" href="/theme/css/style.css">
    <link rel="stylesheet" type="text/css" href="/theme/css/jqcloud.css">
    <link rel="stylesheet" type="text/css" href="/theme/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="/theme/css/pygments-highlight-github.css">

    <!-- Icon -->

    <!-- JavaScript -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script>
    <script src="/theme/js/jqcloud.min.js"></script>
  </head>

  <body>
    <div class="w3-row w3-card w3-white">
      <header id="header">
        <a href="" id="header-logo" title="Home">GN</a>
        <nav id="header-menu">
          <ul>
            <li class="w3-bottombar w3-border-white w3-hover-border-green"><a href="/category/blog">Blog</a></li>
            <li class="w3-bottombar w3-border-white w3-hover-border-green"><a href="/pages/livros">Livros</a></li>
            <li class="w3-bottombar w3-border-white w3-hover-border-green"><a href="/pages/produtos">Produtos</a></li>
            <li class="w3-bottombar w3-border-white w3-hover-border-green"><a href="/pages/sobre">Sobre</a></li>
          </ul>
        </nav>
      </header>
    </div>



    <br><br><br>

    <article>
      <header class="w3-container col-main">
        <h1>Modelo LLM Nemotron 70B: Um primeiro contato</h1>
        <div class="post-info">
          <div class="w3-opacity w3-margin-right w3-margin-bottom" style="flex-grow: 1;">
            <span><time datetime="2024-10-22T00:00:00+02:00">ter 22 outubro 2024</time> in <a href="/category/blog.html" title="All articles in category Blog">Blog</a></span>
          </div>
          <div>
            <span class="w3-tag w3-light-grey w3-text-green w3-hover-green">
              <a href="/tag/redes-neurais.html" title="All articles with Redes Neurais tag">#Redes Neurais</a>
            </span>
            <span class="w3-tag w3-light-grey w3-text-green w3-hover-green">
              <a href="/tag/aprendizagem-de-maquina.html" title="All articles with Aprendizagem De Máquina tag">#Aprendizagem de Máquina</a>
            </span>
            <span class="w3-tag w3-light-grey w3-text-green w3-hover-green">
              <a href="/tag/chatbots.html" title="All articles with Chatbots tag">#Chatbots</a>
            </span>
            <span class="w3-tag w3-light-grey w3-text-green w3-hover-green">
              <a href="/tag/llm.html" title="All articles with Llm tag">#LLM</a>
            </span>
          </div>
        </div>
      </header>

      <br>


      <div class="col-main w3-container">
        <section id="content">
          <p>Em julho de 2024, a Meta lançou um modelo de linguagem (LLM) open-source, o <em>Llama-3.1-70B</em>. Um pouco depois, em setembro a empresa NVIDIA lançou um derivado deste, o <em>Llama 3.1-Nemotron-51B-Instruct</em>. E em outubro lançou finalmente um modelo de 70b customizado, o <em>Llama 3.1 nemotron-70b-instruct</em>.</p>
<p>O <em>nemotron-70b</em> performou melhor, em alguns testes comparativos, do que o GPT-4o. Nos testes, ele liderou em desempenho geral e também se destacou nas categorias chat (<em>chat score</em>) e raciocínio (<em>reasoning score</em>). Veja na <strong>Tabela 1</strong>.</p>
<p><center><strong>Tabela 1</strong> - Comparativo entre Neumotron e GPT4o.</center></p>
<table>
<thead>
<tr>
<th>Model</th>
<th style="text-align: right;">Overall Score</th>
<th style="text-align: right;">Chat Score</th>
<th style="text-align: right;">Reasoning Score</th>
</tr>
</thead>
<tbody>
<tr>
<td>Llama 3.1 Nemotron-70B</td>
<td style="text-align: right;">94.1</td>
<td style="text-align: right;">97.5</td>
<td style="text-align: right;">98.1</td>
</tr>
<tr>
<td>Skywork-Reward-Gemma-2-27B</td>
<td style="text-align: right;">93.8</td>
<td style="text-align: right;">95.8</td>
<td style="text-align: right;">96.1</td>
</tr>
<tr>
<td>TextEval-Llama3.1-70B</td>
<td style="text-align: right;">93.5</td>
<td style="text-align: right;">94.1</td>
<td style="text-align: right;">96.4</td>
</tr>
<tr>
<td>GPT-4o</td>
<td style="text-align: right;">86.7</td>
<td style="text-align: right;">96.1</td>
<td style="text-align: right;">86.6</td>
</tr>
</tbody>
</table>
<p><center>Fonte: <a href="https://build.nvidia.com/nvidia/llama-3_1-nemotron-70b-instruct?snippet_tab=Node">Bind AI</a></center></p>
<p>O Nemontron pode ser testado em <a href="https://build.nvidia.com">build.nvidia.com</a>, especificamente <a href="https://build.nvidia.com/nvidia/llama-3_1-nemotron-70b-instruct?snippet_tab=Node">neste link</a>. A inscrição concede acesso a 100.000 chamadas de API gratuitas. Além disso, ele está disponível para baixar no <a href="https://huggingface.co/nvidia/Llama-3_1-Nemotron-51B-Instruct">Hugging Face</a>. Porém, haja poder de processamento para uma consulta local a este modelo em uma PC de mesa.</p>
<p>Realizei algumas consultas no site da NVIDIA (<strong>Figura 1</strong>) e a velocidade da resposta deixou muito a desejar em relação a quantidade de tokens por minuto. Um versão do <a href="https://console.groq.com/playground">Groq</a> disponível no Groq Cloud (<em>Figura 2</em>), que usa uma versão também customizada do Llama, o <em>llama3-groq-70b-8192-tool-use-preview</em>, é muito mais veloz do que a disponibilizada no site da NVIDIA. Provavelmente isto está relacionado mais ao hardware da Groq, que parece ser mais eficiente, independente do modelo. Cabe ressaltar que a versão da NVIDIA deu uma resposta bem mais completa que a versão do Groq, para o mesmo prompt.</p>
<p><center><strong>Figura 1</strong> - Demonstração do Nemotron 70B no site da NVidea</center></br>
<img src="/images/democracia_nvidia.png" alt="Exemplo do Nemotron" style="width:100%;"/>
<center>Fonte: O Autor (2024)</center></p>
<p><center><strong>Figura 2</strong> - Demonstração no Groq Cloud do modelo 70B tool use preview</center></br>
<img src="/images/democracia_groq.png" alt="Exemplo do Groq Cloud" style="width:100%;"/>
<center>Fonte: O Autor (2024)</center></p>
<p>Um LLM geralmente utiliza a arquitetura <em>transformer</em>, e no Nemotron não foi diferente. Esta arquitetura já é conhecida e permite que o modelo capture dependências de longo alcance no texto, tornando-o apto a compreender o contexto e a gerar respostas.</p>
<p>Outro recurso utilizado é o <em>Attention Multi-Head</em> que permite que o modelo se concentre em diferentes partes da entrada simultaneamente, aprimorando sua capacidade de compreender consultas complexas e produzir resultados diferenciados.</p>
<p>Por fim, foi implementado no modelo, a <em>normalização de camadas</em>. Ela ajuda a estabilizar o treinamento e a melhorar as taxas de convergência, resultando em um aprendizado mais rápido e eficiente.</p>
<p>o modelo foi treinado em uma ampla gama de dados licenciados com a licença (CC-BY-4.0), que inclui livros, artigos e conteúdo da web. Ressaltando que o BY da licença exige que o crédito seja dado ao autor.</p>
<p>De acordo com a NVIDIA, o processo de treinamento do <em>Llama 3.1 Nemotron-70B</em> incluiu: </p>
<ul>
<li>aprendizagem supervisionada </li>
<li>aprendizagem por reforço de feedback humano. </li>
<li>Modelagem de recompensa: O modelo prevê a qualidade da resposta com base nas interações do usuário. Este mecanismo permite ajustar seus resultados de forma dinâmica, melhorando ao longo do tempo com base no feedback do mundo real.</li>
</ul>
<p>Em relação a código, a consulta ao modelo em python utiliza a mesma API do LLM da OpenAI (conforme pode ser visto no código abaixo), alterando somente a <em>base url</em>. </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span>
  <span class="n">base_url</span> <span class="o">=</span> <span class="s2">&quot;https://integrate.api.nvidia.com/v1&quot;</span><span class="p">,</span>
  <span class="n">api_key</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
<span class="p">)</span>

<span class="n">completion</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
  <span class="n">model</span><span class="o">=</span><span class="s2">&quot;nvidia/llama-3.1-nemotron-70b-instruct&quot;</span><span class="p">,</span>
  <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span><span class="s2">&quot;user&quot;</span><span class="p">,</span><span class="s2">&quot;content&quot;</span><span class="p">:</span><span class="s2">&quot;What is machine learning?&quot;</span><span class="p">}],</span>
  <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
  <span class="n">top_p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
  <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
  <span class="n">stream</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">completion</span><span class="p">:</span>
  <span class="k">if</span> <span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Nos vemos no próximo post.</p>
<p>Fontes consultadas:</p>
<p><a href="https://blog.getbind.co/2024/10/17/llama-3-1-nemotron-70b-is-it-better-for-coding-compared-to-gpt-4o-and-claude-3-5-sonnet/">Bind AI Blog post</a></p>
<p><a href="https://creativecommons.org/share-your-work/cclicenses/">CC-BY</a></p>
<p><a href="https://console.groq.com/">GROQ</a></p>
<p><a href="https://developer.nvidia.com/blog/advancing-the-accuracy-efficiency-frontier-with-llama-3-1-nemotron-51b">NVIDIA Blog post</a></p>
<p><a href="https://www.reddit.com/r/LocalLLaMA/comments/1fnp2kt/new_llama31nemotron51b_instruct_model_from_nvidia/">Reddit post</a></p>
        </section>

        <br><br><br>

        <footer>
          <div class="adjust-width">
            <div id="author-block" class="w3-light-grey w3-border">
              <div id="author-info">
                <a href=""><img style="width: 60px; height: 60px;" src="https://0.gravatar.com/avatar/bfb31708333e29b57ed2284eb347ebe10b82b63bae2bfb08c3d80b000103e3aa?size=256" onerror="this.src='theme/images/avatar.png'" alt="Avatar"></a>
                <div style="margin-left: 20px; margin-top: 15px;">
                  <a href=""><span id="author-name" class="w3-hover-text-dark-grey">Giseldo Neo</span></a>
                  <p id="author-story">É pesquisador em inteligência artificial e Professor de Informática.</p>
                </div>
              </div>
            </div>
          </div>

          <br><br><br>

          <p style="font-size:10pt; font-style: italic;">Did you like this article? Share it with your friends!</p>
          <div id="share" class="share">
            <a href="http://www.facebook.com/sharer.php?u=/modelo-llm-nemotron-70b-um-primeiro-contato.html&amp;t=giseldo%3A%20Modelo%20LLM%20Nemotron%2070B%3A%20Um%20primeiro%20contato" target="_blank" class="w3-btn w3-indigo">
              <i class="fa fa-facebook"></i> <span>Facebook</span>
            </a>
            <a href="http://twitter.com/share?url=/modelo-llm-nemotron-70b-um-primeiro-contato.html&amp;text=giseldo%3A%20Modelo%20LLM%20Nemotron%2070B%3A%20Um%20primeiro%20contato" target="_blank" class="w3-btn w3-blue">
              <i class="fa fa-twitter"></i> <span>Twitter</span>
            </a>
            <a href="https://plus.google.com/share?url=/modelo-llm-nemotron-70b-um-primeiro-contato.html" onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;" class="w3-btn w3-red">
              <i class="fa fa-google-plus"></i> <span>Google</span>
            </a>
          </div>

          <br><br><br>


          <div id="disqus_thread"></div>
          <script>
            /**
             *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
             *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
             */
            
            var disqus_config = function () {
              this.page.url = '';  // Replace PAGE_URL with your page's canonical URL variable
              this.page.identifier = 'modelo-llm-nemotron-70b-um-primeiro-contato'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
            };
            
            (function() {  // REQUIRED CONFIGURATION VARIABLE: EDIT THE SHORTNAME BELOW
              var d = document, s = d.createElement('script');
              
              s.src = 'https://giseldo.disqus.com/embed.js';  // IMPORTANT: Replace EXAMPLE with your forum shortname!
              
              s.setAttribute('data-timestamp', +new Date());
              (d.head || d.body).appendChild(s);
            })();
          </script>
          <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
          <br><br><br>

        </footer>
      </div>
    </article>


    <footer id="footer">
      <div id="footer-copyright" class="w3-center w3-small w3-text-grey w3-padding-48">
        <span>&copy;  Giseldo Neo </span>
      </div>
    </footer>



  </body>
</html>