<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 4 Vetorização de Texto | Vetorização de Texto com Python</title>
  <meta name="description" content="Capítulo 4 Vetorização de Texto | Vetorização de Texto com Python" />
  <meta name="generator" content="bookdown 0.38 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 4 Vetorização de Texto | Vetorização de Texto com Python" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 4 Vetorização de Texto | Vetorização de Texto com Python" />
  
  
  

<meta name="author" content="Giseldo Neo" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="pré-processamento-de-texto.html"/>
<link rel="next" href="modelos-avançados-de-vetorização.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Vetorização de Texto com Python</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Informações Adicionais</a></li>
<li class="chapter" data-level="" data-path="prefácio.html"><a href="prefácio.html"><i class="fa fa-check"></i>Prefácio</a></li>
<li class="chapter" data-level="1" data-path="introdução-à-vetorização-de-texto.html"><a href="introdução-à-vetorização-de-texto.html"><i class="fa fa-check"></i><b>1</b> Introdução à Vetorização de Texto</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introdução-à-vetorização-de-texto.html"><a href="introdução-à-vetorização-de-texto.html#conceito-de-vetorização-de-texto"><i class="fa fa-check"></i><b>1.1</b> Conceito de Vetorização de Texto</a></li>
<li class="chapter" data-level="1.2" data-path="introdução-à-vetorização-de-texto.html"><a href="introdução-à-vetorização-de-texto.html#importância-na-análise-de-dados-e-aprendizado-de-máquina"><i class="fa fa-check"></i><b>1.2</b> Importância na Análise de Dados e Aprendizado de Máquina</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introdução-à-vetorização-de-texto.html"><a href="introdução-à-vetorização-de-texto.html#exemplo-em-python"><i class="fa fa-check"></i><b>1.2.1</b> Exemplo em Python</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introdução-à-vetorização-de-texto.html"><a href="introdução-à-vetorização-de-texto.html#aplicações-práticas"><i class="fa fa-check"></i><b>1.3</b> Aplicações Práticas</a></li>
<li class="chapter" data-level="" data-path="introdução-à-vetorização-de-texto.html"><a href="introdução-à-vetorização-de-texto.html#exercícios"><i class="fa fa-check"></i>Exercícios</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="preparação-do-ambiente.html"><a href="preparação-do-ambiente.html"><i class="fa fa-check"></i><b>2</b> Preparação do Ambiente</a>
<ul>
<li class="chapter" data-level="2.1" data-path="preparação-do-ambiente.html"><a href="preparação-do-ambiente.html#instalação-do-python"><i class="fa fa-check"></i><b>2.1</b> Instalação do Python</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="preparação-do-ambiente.html"><a href="preparação-do-ambiente.html#instalando-o-python"><i class="fa fa-check"></i><b>2.1.1</b> Instalando o Python</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="preparação-do-ambiente.html"><a href="preparação-do-ambiente.html#instalação-de-bibliotecas-necessárias"><i class="fa fa-check"></i><b>2.2</b> Instalação de Bibliotecas Necessárias</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="preparação-do-ambiente.html"><a href="preparação-do-ambiente.html#instalando-bibliotecas-com-pip"><i class="fa fa-check"></i><b>2.2.1</b> Instalando Bibliotecas com <code>pip</code></a></li>
<li class="chapter" data-level="2.2.2" data-path="preparação-do-ambiente.html"><a href="preparação-do-ambiente.html#exemplo-em-python-verificando-instalações"><i class="fa fa-check"></i><b>2.2.2</b> Exemplo em Python: Verificando Instalações</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="preparação-do-ambiente.html"><a href="preparação-do-ambiente.html#introdução-ao-jupyter-notebook"><i class="fa fa-check"></i><b>2.3</b> Introdução ao Jupyter Notebook</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="preparação-do-ambiente.html"><a href="preparação-do-ambiente.html#instalando-o-jupyter-notebook"><i class="fa fa-check"></i><b>2.3.1</b> Instalando o Jupyter Notebook</a></li>
<li class="chapter" data-level="2.3.2" data-path="preparação-do-ambiente.html"><a href="preparação-do-ambiente.html#exemplo-em-python-primeiros-passos-no-jupyter"><i class="fa fa-check"></i><b>2.3.2</b> Exemplo em Python: Primeiros Passos no Jupyter</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preparação-do-ambiente.html"><a href="preparação-do-ambiente.html#exercícios-1"><i class="fa fa-check"></i>Exercícios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="pré-processamento-de-texto.html"><a href="pré-processamento-de-texto.html"><i class="fa fa-check"></i><b>3</b> Pré-processamento de Texto</a>
<ul>
<li class="chapter" data-level="3.1" data-path="pré-processamento-de-texto.html"><a href="pré-processamento-de-texto.html#limpeza-de-texto"><i class="fa fa-check"></i><b>3.1</b> Limpeza de Texto</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="pré-processamento-de-texto.html"><a href="pré-processamento-de-texto.html#exemplo-em-python-limpeza-de-texto"><i class="fa fa-check"></i><b>3.1.1</b> Exemplo em Python: Limpeza de Texto</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="pré-processamento-de-texto.html"><a href="pré-processamento-de-texto.html#tokenização"><i class="fa fa-check"></i><b>3.2</b> Tokenização</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="pré-processamento-de-texto.html"><a href="pré-processamento-de-texto.html#exemplo-em-python-tokenização"><i class="fa fa-check"></i><b>3.2.1</b> Exemplo em Python: Tokenização</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="pré-processamento-de-texto.html"><a href="pré-processamento-de-texto.html#lematização-e-stemming"><i class="fa fa-check"></i><b>3.3</b> Lematização e Stemming</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="pré-processamento-de-texto.html"><a href="pré-processamento-de-texto.html#exemplo-em-python-lematização-e-stemming"><i class="fa fa-check"></i><b>3.3.1</b> Exemplo em Python: Lematização e Stemming</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pré-processamento-de-texto.html"><a href="pré-processamento-de-texto.html#exercícios-2"><i class="fa fa-check"></i>Exercícios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="vetorização-de-texto.html"><a href="vetorização-de-texto.html"><i class="fa fa-check"></i><b>4</b> Vetorização de Texto</a>
<ul>
<li class="chapter" data-level="4.1" data-path="vetorização-de-texto.html"><a href="vetorização-de-texto.html#bag-of-words-bow"><i class="fa fa-check"></i><b>4.1</b> Bag of Words (BoW)</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="vetorização-de-texto.html"><a href="vetorização-de-texto.html#exemplo-em-python-bag-of-words"><i class="fa fa-check"></i><b>4.1.1</b> Exemplo em Python: Bag of Words</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="vetorização-de-texto.html"><a href="vetorização-de-texto.html#term-frequency-inverse-document-frequency-tf-idf"><i class="fa fa-check"></i><b>4.2</b> Term Frequency-Inverse Document Frequency (TF-IDF)</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="vetorização-de-texto.html"><a href="vetorização-de-texto.html#exemplo-em-python-tf-idf"><i class="fa fa-check"></i><b>4.2.1</b> Exemplo em Python: TF-IDF</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="vetorização-de-texto.html"><a href="vetorização-de-texto.html#word-embeddings"><i class="fa fa-check"></i><b>4.3</b> Word Embeddings</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="vetorização-de-texto.html"><a href="vetorização-de-texto.html#exemplo-em-python-word2vec"><i class="fa fa-check"></i><b>4.3.1</b> Exemplo em Python: Word2Vec</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="vetorização-de-texto.html"><a href="vetorização-de-texto.html#exercícios-3"><i class="fa fa-check"></i>Exercícios</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="modelos-avançados-de-vetorização.html"><a href="modelos-avançados-de-vetorização.html"><i class="fa fa-check"></i><b>5</b> Modelos Avançados de Vetorização</a>
<ul>
<li class="chapter" data-level="5.1" data-path="modelos-avançados-de-vetorização.html"><a href="modelos-avançados-de-vetorização.html#embeddings-contextuais"><i class="fa fa-check"></i><b>5.1</b> Embeddings Contextuais</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="modelos-avançados-de-vetorização.html"><a href="modelos-avançados-de-vetorização.html#exemplo-em-python-usando-bert-para-vetorização"><i class="fa fa-check"></i><b>5.1.1</b> Exemplo em Python: Usando BERT para Vetorização</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="modelos-avançados-de-vetorização.html"><a href="modelos-avançados-de-vetorização.html#análise-de-sentimento-com-embeddings"><i class="fa fa-check"></i><b>5.2</b> Análise de Sentimento com Embeddings</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="modelos-avançados-de-vetorização.html"><a href="modelos-avançados-de-vetorização.html#exemplo-em-python-classificação-de-sentimento-com-bert"><i class="fa fa-check"></i><b>5.2.1</b> Exemplo em Python: Classificação de Sentimento com BERT</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="modelos-avançados-de-vetorização.html"><a href="modelos-avançados-de-vetorização.html#redução-de-dimensionalidade"><i class="fa fa-check"></i><b>5.3</b> Redução de Dimensionalidade</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="modelos-avançados-de-vetorização.html"><a href="modelos-avançados-de-vetorização.html#exemplo-em-python-redução-de-dimensionalidade-com-pca"><i class="fa fa-check"></i><b>5.3.1</b> Exemplo em Python: Redução de Dimensionalidade com PCA</a></li>
<li class="chapter" data-level="5.3.2" data-path="modelos-avançados-de-vetorização.html"><a href="modelos-avançados-de-vetorização.html#exemplo-em-python-redução-de-dimensionalidade-com-t-sne"><i class="fa fa-check"></i><b>5.3.2</b> Exemplo em Python: Redução de Dimensionalidade com t-SNE</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="modelos-avançados-de-vetorização.html"><a href="modelos-avançados-de-vetorização.html#exercício"><i class="fa fa-check"></i>Exercício</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="aplicações-práticas-1.html"><a href="aplicações-práticas-1.html"><i class="fa fa-check"></i><b>6</b> Aplicações Práticas</a>
<ul>
<li class="chapter" data-level="6.1" data-path="aplicações-práticas-1.html"><a href="aplicações-práticas-1.html#classificação-de-texto-análise-de-sentimento"><i class="fa fa-check"></i><b>6.1</b> Classificação de Texto: Análise de Sentimento</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="aplicações-práticas-1.html"><a href="aplicações-práticas-1.html#exemplo-em-python-classificação-de-texto-com-tf-idf-e-naive-bayes"><i class="fa fa-check"></i><b>6.1.1</b> Exemplo em Python: Classificação de Texto com TF-IDF e Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="aplicações-práticas-1.html"><a href="aplicações-práticas-1.html#agrupamento-de-documentos"><i class="fa fa-check"></i><b>6.2</b> Agrupamento de Documentos</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="aplicações-práticas-1.html"><a href="aplicações-práticas-1.html#exemplo-em-python-agrupamento-com-k-means"><i class="fa fa-check"></i><b>6.2.1</b> Exemplo em Python: Agrupamento com k-means</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="aplicações-práticas-1.html"><a href="aplicações-práticas-1.html#detecção-de-tópicos"><i class="fa fa-check"></i><b>6.3</b> Detecção de Tópicos</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="aplicações-práticas-1.html"><a href="aplicações-práticas-1.html#exemplo-em-python-detecção-de-tópicos-com-lda"><i class="fa fa-check"></i><b>6.3.1</b> Exemplo em Python: Detecção de Tópicos com LDA</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="aplicações-práticas-1.html"><a href="aplicações-práticas-1.html#exercícios-4"><i class="fa fa-check"></i>Exercícios</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estudo-de-caso.html"><a href="estudo-de-caso.html"><i class="fa fa-check"></i><b>7</b> Estudo de Caso</a>
<ul>
<li class="chapter" data-level="7.1" data-path="estudo-de-caso.html"><a href="estudo-de-caso.html#análise-de-reviews-de-produtos"><i class="fa fa-check"></i><b>7.1</b> Análise de Reviews de Produtos</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="estudo-de-caso.html"><a href="estudo-de-caso.html#exemplo-em-python-análise-de-sentimentos-em-reviews-de-produtos"><i class="fa fa-check"></i><b>7.1.1</b> Exemplo em Python: Análise de Sentimentos em Reviews de Produtos</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="estudo-de-caso.html"><a href="estudo-de-caso.html#processamento-de-tweets"><i class="fa fa-check"></i><b>7.2</b> Processamento de Tweets</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="estudo-de-caso.html"><a href="estudo-de-caso.html#exemplo-em-python-análise-de-sentimentos-em-tweets"><i class="fa fa-check"></i><b>7.2.1</b> Exemplo em Python: Análise de Sentimentos em Tweets</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="estudo-de-caso.html"><a href="estudo-de-caso.html#análise-de-notícias"><i class="fa fa-check"></i><b>7.3</b> Análise de Notícias</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="estudo-de-caso.html"><a href="estudo-de-caso.html#exemplo-em-python-modelagem-de-tópicos-em-notícias"><i class="fa fa-check"></i><b>7.3.1</b> Exemplo em Python: Modelagem de Tópicos em Notícias</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="estudo-de-caso.html"><a href="estudo-de-caso.html#exercício-1"><i class="fa fa-check"></i>Exercício</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="próximos-passos.html"><a href="próximos-passos.html"><i class="fa fa-check"></i><b>8</b> Próximos Passos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="próximos-passos.html"><a href="próximos-passos.html#futuras-direções-no-campo-de-vetorização-de-texto"><i class="fa fa-check"></i><b>8.1</b> Futuras Direções no Campo de Vetorização de Texto</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="próximos-passos.html"><a href="próximos-passos.html#modelos-de-linguagem-de-grande-escala"><i class="fa fa-check"></i><b>8.1.1</b> Modelos de Linguagem de Grande Escala</a></li>
<li class="chapter" data-level="8.1.2" data-path="próximos-passos.html"><a href="próximos-passos.html#multimodalidade"><i class="fa fa-check"></i><b>8.1.2</b> Multimodalidade</a></li>
<li class="chapter" data-level="8.1.3" data-path="próximos-passos.html"><a href="próximos-passos.html#vetorização-de-texto-em-tempo-real"><i class="fa fa-check"></i><b>8.1.3</b> Vetorização de Texto em Tempo Real</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="próximos-passos.html"><a href="próximos-passos.html#leitura-recomendada"><i class="fa fa-check"></i><b>8.2</b> Leitura Recomendada</a></li>
<li class="chapter" data-level="8.3" data-path="próximos-passos.html"><a href="próximos-passos.html#próximos-passos-1"><i class="fa fa-check"></i><b>8.3</b> Próximos Passos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="gabarito-das-questões.html"><a href="gabarito-das-questões.html"><i class="fa fa-check"></i>Gabarito das questões</a></li>
<li class="chapter" data-level="" data-path="sobre-os-autores.html"><a href="sobre-os-autores.html"><i class="fa fa-check"></i>Sobre os autores</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Vetorização de Texto com Python</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="vetorização-de-texto" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Capítulo 4</span> Vetorização de Texto<a href="vetorização-de-texto.html#vetorização-de-texto" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Neste capítulo, exploraremos as diferentes técnicas de vetorização de
texto, que são essenciais para transformar dados textuais em uma forma
numérica que pode ser utilizada por algoritmos de aprendizado de
máquina. Abordaremos o <em>Bag of Words</em> (BoW), <em>TF-IDF</em> e <em>Word
Embeddings</em>, com exemplos práticos em Python.</p>
<div id="bag-of-words-bow" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Bag of Words (BoW)<a href="vetorização-de-texto.html#bag-of-words-bow" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>O <em>Bag of Words</em> (BoW) é uma das técnicas mais simples de vetorização de
texto. Ele representa um texto como um conjunto de palavras,
desconsiderando a ordem das palavras, mas mantendo a multiplicidade. Ele
simplifica a representação textual para que possa ser utilizada em
tarefas de aprendizado de máquina. Imagine um texto como um saco onde
jogamos todas as palavras, desconsiderando a ordem em que elas aparecem
e contando apenas a frequência com que cada uma delas ocorre.</p>
<p>Como funciona:</p>
<ol style="list-style-type: decimal">
<li><p>Tokenização: O texto é dividido em unidades individuais, geralmente
palavras.</p></li>
<li><p>Criação do Vocabulário: É criado um conjunto de todas as palavras
únicas presentes em um corpus de textos.</p></li>
<li><p>Representação Vetorial: Cada documento é representado como um vetor
numérico, onde cada posição corresponde a uma palavra do vocabulário
e o valor numérico indica a frequência dessa palavra no documento.</p></li>
</ol>
<p>Por exemplo, considere dois documentos:</p>
<ul>
<li><p>Documento 1: "O gato subiu na árvore."</p></li>
<li><p>Documento 2: "O cachorro latindo para o gato."</p></li>
</ul>
<p>O vocabulário seria: o, gato, subiu, na, árvore, cachorro, latindo,
para. A representação vetorial dos documentos poderia ser:</p>
<ul>
<li><p>Documento 1: <span class="math display">\[1, 2, 1, 1, 1, 0, 0, 0\]</span></p></li>
<li><p>Documento 2: <span class="math display">\[1, 1, 0, 0, 0, 1, 1, 1\]</span></p></li>
</ul>
<p>O Bag-of-Words é fácil de implementar e entender; permite a aplicação de
algoritmos de aprendizado de máquina em grandes volumes de texto; além
disso, pode ser utilizado em diversas tarefas de PLN, como classificação
de textos, clustering e recuperação de informação.</p>
<p>Algumas Limitações é que ele ignora a ordem das palavras e a estrutura
gramatical, o que pode levar à perda de significado; além disso existe
uma dificuldade em lidar com sinônimos e palavras ambíguas, pois,
palavras com significados semelhantes podem ser tratadas como diferentes
e palavras com múltiplos significados podem causar ambiguidade.</p>
<p>Algumas aplicações são: a classificação de textos para identificar a
categoria de um texto (por exemplo, spam ou não spam); a clusterização,
ou seja, agrupar documentos semelhantes; outra é a recuperação de
informação para encontrar documentos relevantes em resposta a uma
consulta; além disso, a análise de sentimentos para determinar a
polaridade de um texto (positivo, negativo ou neutro).</p>
<div id="exemplo-em-python-bag-of-words" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Exemplo em Python: Bag of Words<a href="vetorização-de-texto.html#exemplo-em-python-bag-of-words" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb16" language="Python" caption="Código Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="vetorização-de-texto.html#cb16-1" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb16-2"><a href="vetorização-de-texto.html#cb16-2" tabindex="-1"></a></span>
<span id="cb16-3"><a href="vetorização-de-texto.html#cb16-3" tabindex="-1"></a><span class="co"># Exemplo de documentos</span></span>
<span id="cb16-4"><a href="vetorização-de-texto.html#cb16-4" tabindex="-1"></a>documentos <span class="op">=</span> [</span>
<span id="cb16-5"><a href="vetorização-de-texto.html#cb16-5" tabindex="-1"></a><span class="st">&quot;existe gato laranja&quot;</span>,</span>
<span id="cb16-6"><a href="vetorização-de-texto.html#cb16-6" tabindex="-1"></a><span class="st">&quot;existe gato preto&quot;</span>,</span>
<span id="cb16-7"><a href="vetorização-de-texto.html#cb16-7" tabindex="-1"></a><span class="st">&quot;também existe gato branco&quot;</span></span>
<span id="cb16-8"><a href="vetorização-de-texto.html#cb16-8" tabindex="-1"></a>]</span>
<span id="cb16-9"><a href="vetorização-de-texto.html#cb16-9" tabindex="-1"></a></span>
<span id="cb16-10"><a href="vetorização-de-texto.html#cb16-10" tabindex="-1"></a><span class="co"># Criação do modelo BoW</span></span>
<span id="cb16-11"><a href="vetorização-de-texto.html#cb16-11" tabindex="-1"></a>vectorizer <span class="op">=</span> CountVectorizer()</span>
<span id="cb16-12"><a href="vetorização-de-texto.html#cb16-12" tabindex="-1"></a>X <span class="op">=</span> vectorizer.fit_transform(documentos)</span>
<span id="cb16-13"><a href="vetorização-de-texto.html#cb16-13" tabindex="-1"></a></span>
<span id="cb16-14"><a href="vetorização-de-texto.html#cb16-14" tabindex="-1"></a><span class="co"># Exibição da matriz BoW</span></span>
<span id="cb16-15"><a href="vetorização-de-texto.html#cb16-15" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Vetor de características:</span><span class="ch">\n</span><span class="st">&quot;</span>, vectorizer.</span>
<span id="cb16-16"><a href="vetorização-de-texto.html#cb16-16" tabindex="-1"></a>get_feature_names_out())</span>
<span id="cb16-17"><a href="vetorização-de-texto.html#cb16-17" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Matriz BoW:</span><span class="ch">\n</span><span class="st">&quot;</span>, X.toarray())</span></code></pre></div>
<pre caption="Saída do console"><code>Vetor de características:
[&#39;branco&#39; &#39;existe&#39; &#39;gato&#39; &#39;laranja&#39; &#39;preto&#39; &#39;também&#39;]
Matriz BoW:
[[0 1 1 1 0 0]
[0 1 1 0 1 0]
[1 1 1 0 0 1]]</code></pre>
<p>Este código gera uma matriz BoW, onde cada linha representa um documento
e cada coluna representa uma palavra única do vocabulário.</p>
</div>
</div>
<div id="term-frequency-inverse-document-frequency-tf-idf" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Term Frequency-Inverse Document Frequency (TF-IDF)<a href="vetorização-de-texto.html#term-frequency-inverse-document-frequency-tf-idf" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>O <em>TF-IDF</em> é uma técnica de vetorização que leva em consideração a
frequência das palavras em um documento em relação a um corpus de
documentos. Ele pondera as palavras de acordo com sua importância
relativa, diminuindo o peso das palavras comuns e aumentando o peso das
palavras menos frequentes. Em termos simples, o TF-IDF nos ajuda a
entender quais palavras são mais relevantes e distintivas em um texto
específico, comparando-o com outros textos. Utilizando essa técnica, é
possível extrair uma métrica estatística para avaliar a importância de
uma palavra em um documento em relação a um conjunto de documentos.
permitindo assim analisar e entender o conteúdo de grandes volumes de
texto.</p>
<p>TF (Term Frequency): Mede a frequência com que uma palavra aparece em um
documento. Quanto mais vezes uma palavra aparece, maior é seu TF. IDF
(Inverse Document Frequency): Mede a raridade de uma palavra em um
conjunto de documentos. Palavras que aparecem em muitos documentos têm
um IDF baixo, enquanto palavras que aparecem em poucos documentos têm um
IDF alto.</p>
<p>O valor TF-IDF é o produto do TF e do IDF:</p>
<pre><code>TF-IDF(t, d) = TF(t, d) * IDF(t)</code></pre>
<p>Onde:</p>
<ul>
<li><p>‘t’ é um termo (palavra)</p></li>
<li><p>‘d’ é um documento</p></li>
</ul>
<p>Por exemplo, imagine um conjunto de documentos sobre carros. A palavra
"carro" provavelmente terá um TF alto em todos os documentos, mas um
IDF baixo, pois é muito comum. Já a palavra "supercarro" pode ter um
TF baixo em muitos documentos, mas um IDF alto, pois é menos comum. O
TF-IDF da palavra "supercarro" será maior do que o da palavra
"carro", indicando que "supercarro" é mais distintiva e relevante
para identificar documentos sobre carros esportivos.</p>
<p>Alguns exemplos do uso de TF-IDF: recuperação de informação, para
ranquear documentos em resposta a uma consulta de pesquisa; mineração de
texto, para identificar tópicos e padrões em grandes conjuntos de
documentos. E sistemas de recomendação, para sugerir itens relevantes
aos usuários. Ao combinar informações sobre a frequência de palavras em
um documento e sua raridade em um conjunto de documentos, o TF-IDF nos
permite identificar as palavras mais importantes e relevantes para um
determinado contexto.</p>
<div id="exemplo-em-python-tf-idf" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Exemplo em Python: TF-IDF<a href="vetorização-de-texto.html#exemplo-em-python-tf-idf" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb19" language="Python" caption="Código Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="vetorização-de-texto.html#cb19-1" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb19-2"><a href="vetorização-de-texto.html#cb19-2" tabindex="-1"></a></span>
<span id="cb19-3"><a href="vetorização-de-texto.html#cb19-3" tabindex="-1"></a><span class="co"># Exemplo de documentos</span></span>
<span id="cb19-4"><a href="vetorização-de-texto.html#cb19-4" tabindex="-1"></a>documentos <span class="op">=</span> [</span>
<span id="cb19-5"><a href="vetorização-de-texto.html#cb19-5" tabindex="-1"></a><span class="st">&quot;existe gato laranja&quot;</span>,</span>
<span id="cb19-6"><a href="vetorização-de-texto.html#cb19-6" tabindex="-1"></a><span class="st">&quot;existe gato preto&quot;</span>,</span>
<span id="cb19-7"><a href="vetorização-de-texto.html#cb19-7" tabindex="-1"></a><span class="st">&quot;também existe gato branco&quot;</span></span>
<span id="cb19-8"><a href="vetorização-de-texto.html#cb19-8" tabindex="-1"></a>]</span>
<span id="cb19-9"><a href="vetorização-de-texto.html#cb19-9" tabindex="-1"></a></span>
<span id="cb19-10"><a href="vetorização-de-texto.html#cb19-10" tabindex="-1"></a><span class="co"># Criação do modelo TF-IDF</span></span>
<span id="cb19-11"><a href="vetorização-de-texto.html#cb19-11" tabindex="-1"></a>tfidf_vectorizer <span class="op">=</span> TfidfVectorizer()</span>
<span id="cb19-12"><a href="vetorização-de-texto.html#cb19-12" tabindex="-1"></a>X_tfidf <span class="op">=</span> tfidf_vectorizer.fit_transform(documentos)</span>
<span id="cb19-13"><a href="vetorização-de-texto.html#cb19-13" tabindex="-1"></a></span>
<span id="cb19-14"><a href="vetorização-de-texto.html#cb19-14" tabindex="-1"></a><span class="co"># Exibição da matriz TF-IDF</span></span>
<span id="cb19-15"><a href="vetorização-de-texto.html#cb19-15" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Vetor de características:</span><span class="ch">\n</span><span class="st">&quot;</span>, tfidf_vectorizer.get_feature_names_out())</span>
<span id="cb19-16"><a href="vetorização-de-texto.html#cb19-16" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Matriz TF-IDF:</span><span class="ch">\n</span><span class="st">&quot;</span>, X_tfidf.toarray())</span></code></pre></div>
<pre caption="Saída do Console"><code>Vetor de características:
[&#39;branco&#39; &#39;existe&#39; &#39;gato&#39; &#39;laranja&#39; &#39;preto&#39; &#39;também&#39;]
Matriz TF-IDF:
[[0.         0.45329466 0.45329466 0.76749457 0.         0.        ]
[0.         0.45329466 0.45329466 0.         0.76749457 0.        ]
[0.6088451  0.35959372 0.35959372 0.         0.         0.6088451 ]]</code></pre>
<p>Este código gera uma matriz TF-IDF, onde cada valor representa a
importância de uma palavra em um documento em relação ao corpus.</p>
</div>
</div>
<div id="word-embeddings" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Word Embeddings<a href="vetorização-de-texto.html#word-embeddings" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Os <em>Word Embeddings</em> são representações densas de palavras em um espaço
vetorial, que capturam as relações semânticas entre as palavras.
Técnicas como <em>Word2Vec</em>, <em>GloVe</em> e <em>FastText</em> são amplamente utilizadas
para gerar embeddings que refletem o contexto em que as palavras
aparecem.</p>
<div id="exemplo-em-python-word2vec" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Exemplo em Python: Word2Vec<a href="vetorização-de-texto.html#exemplo-em-python-word2vec" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb21" language="Python" caption="Código Python"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="vetorização-de-texto.html#cb21-1" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> Word2Vec</span>
<span id="cb21-2"><a href="vetorização-de-texto.html#cb21-2" tabindex="-1"></a></span>
<span id="cb21-3"><a href="vetorização-de-texto.html#cb21-3" tabindex="-1"></a><span class="co"># Exemplo de corpus</span></span>
<span id="cb21-4"><a href="vetorização-de-texto.html#cb21-4" tabindex="-1"></a>corpus <span class="op">=</span> [</span>
<span id="cb21-5"><a href="vetorização-de-texto.html#cb21-5" tabindex="-1"></a>[<span class="st">&quot;existe&quot;</span>, <span class="st">&quot;gato&quot;</span>, <span class="st">&quot;laranja&quot;</span>],</span>
<span id="cb21-6"><a href="vetorização-de-texto.html#cb21-6" tabindex="-1"></a>[<span class="st">&quot;existe&quot;</span>, <span class="st">&quot;gato&quot;</span>, <span class="st">&quot;preto&quot;</span>],</span>
<span id="cb21-7"><a href="vetorização-de-texto.html#cb21-7" tabindex="-1"></a>[<span class="st">&quot;também&quot;</span>, <span class="st">&quot;existe&quot;</span>, <span class="st">&quot;gato&quot;</span>, <span class="st">&quot;branco&quot;</span>]</span>
<span id="cb21-8"><a href="vetorização-de-texto.html#cb21-8" tabindex="-1"></a>]</span>
<span id="cb21-9"><a href="vetorização-de-texto.html#cb21-9" tabindex="-1"></a></span>
<span id="cb21-10"><a href="vetorização-de-texto.html#cb21-10" tabindex="-1"></a><span class="co"># Treinamento do modelo Word2Vec</span></span>
<span id="cb21-11"><a href="vetorização-de-texto.html#cb21-11" tabindex="-1"></a>model <span class="op">=</span> Word2Vec(sentences<span class="op">=</span>corpus, vector_size<span class="op">=</span><span class="dv">100</span>, window<span class="op">=</span><span class="dv">5</span>, min_count<span class="op">=</span><span class="dv">1</span>, workers<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb21-12"><a href="vetorização-de-texto.html#cb21-12" tabindex="-1"></a></span>
<span id="cb21-13"><a href="vetorização-de-texto.html#cb21-13" tabindex="-1"></a><span class="co"># Obtenção do embedding para uma palavra</span></span>
<span id="cb21-14"><a href="vetorização-de-texto.html#cb21-14" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Embedding para &#39;gato&#39;:</span><span class="ch">\n</span><span class="st">&quot;</span>, model.wv[<span class="st">&quot;gato&quot;</span>])</span>
<span id="cb21-15"><a href="vetorização-de-texto.html#cb21-15" tabindex="-1"></a></span>
<span id="cb21-16"><a href="vetorização-de-texto.html#cb21-16" tabindex="-1"></a><span class="co"># Similaridade entre palavras</span></span>
<span id="cb21-17"><a href="vetorização-de-texto.html#cb21-17" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Similaridade entre &#39;gato&#39; e &#39;laranja&#39;:&quot;</span>, model.wv.</span>
<span id="cb21-18"><a href="vetorização-de-texto.html#cb21-18" tabindex="-1"></a>similarity(<span class="st">&quot;gato&quot;</span>, <span class="st">&quot;laranja&quot;</span>))</span></code></pre></div>
<pre caption="Saída do console"><code>Embedding para &#39;gato&#39;:
[-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03
-9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03
-5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03
-4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03
2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03
7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04
6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03
-7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04
9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03
8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03
-9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03
-3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03
4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03
-4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03
4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03
-1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03
-1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03
-2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03
-1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04
7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03
-8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03
-5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03
-3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04
3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03
-8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]
Similaridade entre &#39;gato&#39; e &#39;laranja&#39;: -0.05987629</code></pre>
<p>Este exemplo treina um modelo <em>Word2Vec</em> e calcula a similaridade entre
os vetores de duas palavras.</p>
<p>Em resumo, a vetorização de texto é um passo crucial na preparação de
dados para modelos de aprendizado de máquina. Técnicas como BoW, TF-IDF
e Word Embeddings fornecem maneiras eficazes de transformar texto em uma
forma que possa ser utilizada para diversas tarefas de processamento de
linguagem natural.</p>
</div>
</div>
<div id="exercícios-3" class="section level2 unnumbered hasAnchor">
<h2>Exercícios<a href="vetorização-de-texto.html#exercícios-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Versão on-line destes exercícios</p>
<p><a href="https://forms.gle/euESDhq7hYWoCSGSA" class="uri">https://forms.gle/euESDhq7hYWoCSGSA</a></p>
<ol style="list-style-type: decimal">
<li><p><strong>Qual é a principal característica do modelo Bag of Words (BoW)?</strong></p>
<ol style="list-style-type: decimal">
<li><p>Considera a ordem das palavras no texto.</p></li>
<li><p>Ignora a ordem das palavras, mas mantém a contagem de frequência
das palavras.</p></li>
<li><p>Gera representações vetoriais densas das palavras.</p></li>
<li><p>Utiliza embeddings contextuais para representar palavras.</p></li>
</ol></li>
<li><p><strong>O que o termo TF-IDF representa?</strong></p>
<ol style="list-style-type: decimal">
<li><p>Transform Frequency-Inverse Document Frequency.</p></li>
<li><p>Term Frequency-Inverse Document Frequency.</p></li>
<li><p>Term Frequency-Indexed Document Frequency.</p></li>
<li><p>Transform Frequency-Indexed Document Frequency.</p></li>
</ol></li>
<li><p><strong>Qual é uma vantagem dos Word Embeddings em relação ao modelo Bag
of Words?</strong></p>
<ol style="list-style-type: decimal">
<li><p>Word Embeddings capturam a ordem das palavras no texto.</p></li>
<li><p>Word Embeddings geram vetores esparsos de alta dimensionalidade.</p></li>
<li><p>Word Embeddings capturam relações semânticas entre palavras.</p></li>
<li><p>Word Embeddings ignoram a frequência das palavras no texto.</p></li>
</ol></li>
<li><p><strong>Qual biblioteca Python tem uma implementação do TF-IDF?</strong></p>
<ol style="list-style-type: decimal">
<li><p>NumPy.</p></li>
<li><p>Pandas.</p></li>
<li><p>Scikit-learn.</p></li>
<li><p>RE.</p></li>
</ol></li>
<li><p><strong>Qual técnica é utilizada para criar representações vetoriais
densas que capturam o significado semântico das palavras?</strong></p>
<ol style="list-style-type: decimal">
<li><p>Bag of Words.</p></li>
<li><p>TF-IDF.</p></li>
<li><p>Word Embeddings.</p></li>
<li><p>N-grams.</p></li>
</ol></li>
</ol>
</div>
</div>
<script async defer src="https://hypothes.is/embed.js"></script>
<link href='https://fonts.googleapis.com/css?family=Arvo' rel='stylesheet' type='text/css'>
<link href='https://fonts.googleapis.com/css?family=Arvo' rel='stylesheet' type='text/css'>
            </section>

          </div>
        </div>
      </div>
<a href="pré-processamento-de-texto.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modelos-avançados-de-vetorização.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
