---
title: 'CodeGPT Primeiro Contato'
date: '2024-11-19'
draft: false
tags: ["Python", "Large Language Models", "Meta"]
---

**CodeGPT revoluciona o desenvolvimento de software com IA avançada**  

O **CodeGPT** se tornou um dos assistentes de codificação mais populares, integrando-se a IDEs como Visual Studio Code e JetBrains. Desde seu lançamento em março de 2023, acumulou mais de **1,4 milhão de downloads** e está presente em mais de 180 países, ajudando desenvolvedores e CTOs a aumentar sua produtividade em **30%** ou mais.  

A integração com o modelo de linguagem **Llama**, da Meta, foi um divisor de águas para a plataforma. Com a adoção do Llama 3.2 (90B), o CodeGPT evoluiu de gerador de código para uma solução completa de assistência, capaz de:  
- **Gerar estruturas de projetos e arquivos automaticamente**  
- **Compreender repositórios complexos** por meio de gráficos de código  
- Simplificar o **onboarding de novos desenvolvedores**  
- Melhorar a depuração e criação de código.  

Essa transformação exigiu desafios como o ajuste do Llama para compreender fluxos de trabalho complexos e tarefas em etapas, além de otimizações específicas para diferentes linguagens e cenários de programação. A adoção de código aberto foi essencial nesse processo, permitindo acesso a tecnologias de ponta e conectando a equipe a uma comunidade global de desenvolvedores.  

Para o futuro, o CodeGPT planeja recursos inovadores, como **colaboração em tempo real** e ferramentas avançadas de **refatoração de código**, solidificando sua posição como líder em IA para desenvolvimento.  

Com o apoio de modelos abertos como Llama, o CodeGPT prova que é possível inovar rapidamente, mesmo com recursos limitados, revolucionando fluxos de trabalho e tornando a programação mais intuitiva. 

Fiz um pequeno exemplo com o CodeGPT (veja na imagem abaixo) utilizando a estrutura condicional se (IF). Fiz um pequeno exemplo e solicitei para o CodeGPT explicar o código com o comando \explain. Antes tive que selecionar a versão do LLM utilizado, escolhi o Llama 3.2 com 90 bilhões de parâmetros que está disponível no GROQ do ElonMusk. O GROQ é uma startup que fornece e produz uma estrutura de hardware com alta velocidade para inferência em modelos LLM. o GROQ tem uma velocidade considerável em relação aos seus concorrentes, talvez perca para o ChatGPT em relação assertividade.

![image](https://github.com/user-attachments/assets/5f09e44e-bcbe-484d-a4dd-b8bc3009fcb1)
<center>Fonte: o Autor (2024)</center>

Até o próximo post.

Fonte consultada: 
  - https://ai.meta.com/blog/codegpt-built-with-llama/?utm_source=email&utm_medium=developer-newsletter-november-2024&utm_campaign=organic&utm_content=body-button-Built-with-Llama%3A-CodeGPT&utm_offering=AI&utm_type=Blog-Article&utm_funnel=Educate&utm_location=1&content_id=TkzndUMQnFYTRss
  - https://groq.com/
  - https://marketplace.visualstudio.com/items?itemName=DanielSanMedium.dscodegpt&ssr=true#overview
