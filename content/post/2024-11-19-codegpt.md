---
title: "CodeGPT Primeiro Contato"
subtitle: "Uma ferramenta de LLM para auxiliar o desenvolvimento"
author: "Giseldo Neo"
date: "2024-11-19"
draft: false
tags: ["Python", "Large Language Models", "Meta"]
---

**CodeGPT revoluciona o desenvolvimento de software com IA avançada**  

O **CodeGPT** se tornou um dos assistentes de codificação mais populares, integrando-se a IDEs como Visual Studio Code e JetBrains. Desde seu lançamento em março de 2023, acumulou mais de **1,4 milhão de downloads** e está presente em mais de 180 países, ajudando desenvolvedores a aumentar sua produtividade em **30%** ou mais.  

A integração com o modelo de linguagem **Llama**, da Meta, foi um divisor de águas para a plataforma. Com a adoção do Llama 3.2 (90B), o CodeGPT evoluiu de gerador de código para uma solução completa de assistência, capaz de:  
- **Gerar estruturas de projetos e arquivos automaticamente**  
- **Compreender repositórios complexos** por meio de gráficos de código  
- Simplificar o **onboarding de novos desenvolvedores**  
- Melhorar a depuração e criação de código.  

Essa transformação exigiu desafios como o ajuste do Llama para compreender fluxos de trabalho complexos e tarefas em etapas, além de otimizações específicas para diferentes linguagens e cenários de programação. A adoção de código aberto foi essencial nesse processo, permitindo acesso a tecnologias de ponta e conectando a equipe a uma comunidade global de desenvolvedores.  

Para o futuro, o CodeGPT planeja recursos, tais como, **colaboração em tempo real** e ferramentas avançadas de **refatoração de código**.  Com o apoio de modelos abertos como Llama, o CodeGPT prova que é possível inovar rapidamente revolucionando fluxos de trabalho e tornando a programação mais intuitiva. 

Fiz um pequeno exemplo com o CodeGPT (veja na imagem abaixo) utilizando a estrutura condicional **Se-Então**. Fiz um pequeno exemplo em python e solicitei ao CodeGPT a explição do código com o comando \explain. Antes tive que selecionar a versão do LLM utilizado, escolhi o Llama 3.2 com 90 bilhões de parâmetros que está disponível no GROQ. O GROQ é uma startup que fornece e produz uma estrutura de hardware com alta velocidade para inferência em modelos LLM. o GROQ tem uma velocidade considerável em relação aos seus concorrentes.

![image](https://github.com/user-attachments/assets/5f09e44e-bcbe-484d-a4dd-b8bc3009fcb1)
Fonte: o Autor (2024)

Curtiu? Deixei um comentário. Até o próximo post.

**Referências**

- https://ai.meta.com/blog/codegpt-built-with-llama/?utm_source=email&utm_medium=developer-newsletter-november-2024&utm_campaign=organic&utm_content=body-button-Built-with-Llama%3A-CodeGPT&utm_offering=AI&utm_type=Blog-Article&utm_funnel=Educate&utm_location=1&content_id=TkzndUMQnFYTRss
- https://groq.com/
- https://marketplace.visualstudio.com/items?itemName=DanielSanMedium.dscodegpt&ssr=true#overview
